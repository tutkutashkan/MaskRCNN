{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Tutku Tashkan 17/03/2023\n",
    "\n",
    "import os\n",
    "from os.path import exists, join, basename, splitext\n",
    "\n",
    "import random\n",
    "import PIL\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import wget\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tutku\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tutku\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model = model.eval().cpu()\n",
    "\n",
    "coco_names = ['unlabeled', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'street sign', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'hat', 'backpack', 'umbrella', 'shoe', 'eye glasses', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'mirror', 'dining table', 'window', 'desk', 'toilet', 'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "colors = [[random.randint(0, 255) for _ in range(3)] for _ in coco_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executed in 4.057s\n",
      "executed in 4.904s\n",
      "executed in 3.932s\n",
      "executed in 3.600s\n",
      "executed in 3.296s\n",
      "executed in 3.291s\n",
      "executed in 3.245s\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)  # Open the first camera connected to the computer\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read the camera frame\n",
    "\n",
    "    if ret:\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Convert to PIL Image\n",
    "        image = PIL.Image.fromarray(frame)\n",
    "\n",
    "        t = time.time()\n",
    "        image_tensor = torchvision.transforms.functional.to_tensor(image).cpu()\n",
    "        output = model([image_tensor])[0]\n",
    "        print('executed in %.3fs' % (time.time() - t))\n",
    "\n",
    "        result_image = np.array(image.copy())\n",
    "\n",
    "        for box, label, score, mask in zip(output['boxes'], output['labels'], output['scores'], output['masks']):\n",
    "\n",
    "            if score > 0.5:\n",
    "                color = colors[label]\n",
    "\n",
    "                # Draw box\n",
    "                tl = round(0.002 * max(result_image.shape[0:2])) + 1  # line thickness\n",
    "                c1, c2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n",
    "                cv2.rectangle(result_image, c1, c2, color, thickness=tl)\n",
    "\n",
    "                # Draw text\n",
    "                display_txt = \"%s: %.1f%%\" % (coco_names[label], 100*score)\n",
    "                tf = max(tl - 1, 1)  # font thickness\n",
    "                t_size = cv2.getTextSize(display_txt, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "                c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "                cv2.rectangle(result_image, c1, c2, color, -1)  # filled\n",
    "                cv2.putText(result_image, display_txt, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "\n",
    "                mask_np = mask.squeeze().cpu().numpy()\n",
    "                \n",
    "                # Calculate center point\n",
    "                xy = np.where(mask_np>0)\n",
    "                y = xy[0]\n",
    "                x = xy[1]\n",
    "                center = np.array([x.mean(), y.mean()])\n",
    "                center = center.astype(int)\n",
    "\n",
    "                # Perform PCA on mask\n",
    "                coords = np.vstack([x, y])\n",
    "                cov = np.cov(coords)\n",
    "                evals, evecs = np.linalg.eig(cov)\n",
    "                sort_indices = np.argsort(evals)[::-1]\n",
    "                evec1, evec2 = evecs[:, sort_indices]\n",
    "                principal_axes = evecs[:, sort_indices[:2]]\n",
    "\n",
    "                # Compute the angle between the first principal axis and the x-axis\n",
    "                angle = math.atan2(principal_axes[1,0], principal_axes[0,0])\n",
    "\n",
    "                # Length of the lines\n",
    "                length1 = int(2 * math.sqrt(evals[sort_indices[0]]))\n",
    "                length2 = int(2 * math.sqrt(evals[sort_indices[1]]))\n",
    "                endpoint1 = (int(center[0] + length1 * math.cos(angle)), int(center[1] + length1 * math.sin(angle)))\n",
    "                endpoint2 = (int(center[0] - length2 * math.sin(angle)), int(center[1] + length2 * math.cos(angle)))\n",
    "\n",
    "                # Draw the circle and the lines\n",
    "                cv2.circle(result_image, center, 5, (0, 255, 0), 2)\n",
    "                cv2.line(result_image, center, endpoint1, (0, 0, 255), 2)\n",
    "                cv2.line(result_image, center, endpoint2, (255, 0, 0), 2)\n",
    "\n",
    "                # Overlay the mask\n",
    "                mask = cv2.resize(mask_np, (result_image.shape[1], result_image.shape[0]))\n",
    "                mask = mask.astype(np.float32) * 0.5\n",
    "                result_image = (result_image.astype(np.float32) + mask[:, :, np.newaxis] * color).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        cv2.imshow('Mask R-CNN output', result_image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
